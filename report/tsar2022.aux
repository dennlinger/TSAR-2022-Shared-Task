\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{sutton-2019-bitter}
\citation{vaswani-etal-2017-attention,wei-etal-2022-emergent}
\citation{ferres-etal-2017-adaptable,qiang-etal-2020-lexical,stajner-etal-2022-lexical}
\citation{tsar-2022-findings}
\citation{brown-etal-2020-language}
\citation{thoppilan-etal-2022-lambda,bigscience-2022-bloom,zhang-etal-2022-opt}
\citation{qiang-etal-2020-lexical}
\citation{ferres-etal-2017-adaptable}
\citation{qiang-etal-2020-lexical}
\citation{ferres-etal-2017-adaptable}
\bibdata{anthology,custom}
\bibcite{bigscience-2022-bloom}{{1}{2022}{{BigScience}}{{}}}
\bibcite{brown-etal-2020-language}{{2}{2020}{{Brown et~al.}}{{Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and Amodei}}}
\bibcite{ferres-etal-2017-adaptable}{{3}{2017}{{Ferr{\'e}s et~al.}}{{Ferr{\'e}s, Saggion, and G{\'o}mez~Guinovart}}}
\bibcite{qiang-etal-2020-lexical}{{4}{2020}{{Qiang et~al.}}{{Qiang, Li, Yi, Yuan, and Wu}}}
\bibcite{tsar-2022-findings}{{5}{2022}{{Saggion et~al.}}{{Saggion, \v {S}tajner, Ferr{\'e}s, Sheang, Shardlow, North, and Zampieri}}}
\bibcite{sutton-2019-bitter}{{6}{2019}{{Sutton}}{{}}}
\bibcite{thoppilan-etal-2022-lambda}{{7}{2022}{{Thoppilan et~al.}}{{Thoppilan, Freitas, Hall, Shazeer, Kulshreshtha, Cheng, Jin, Bos, Baker, Du, Li, Lee, Zheng, Ghafouri, Menegali, Huang, Krikun, Lepikhin, Qin, Chen, Xu, Chen, Roberts, Bosma, Zhou, Chang, Krivokon, Rusch, Pickett, Meier{-}Hellstern, Morris, Doshi, Santos, Duke, Soraker, Zevenbergen, Prabhakaran, Diaz, Hutchinson, Olson, Molina, Hoffman{-}John, Lee, Aroyo, Rajakumar, Butryna, Lamm, Kuzmina, Fenton, Cohen, Bernstein, Kurzweil, Aguera{-}Arcas, Cui, Croak, Chi, and Le}}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:english}{{1}{3}{Results on the English language test set of the TSAR-2022 shared task, ranked by \emph {ACC@1} scores. Listed are our own results (\emph {Ensemble} and \emph {Single}), the two best-performing competing systems~(\emph {MANTIS} and \emph {UoM\&MMU}), as well as provided baselines (\emph {LSBert}~\cite {qiang-etal-2020-lexical} and TUNER~\cite {ferres-etal-2017-adaptable}).\relax }{table.caption.1}{}}
\newlabel{tab:english@cref}{{[table][1][]1}{[1][2][]3}}
\bibcite{vaswani-etal-2017-attention}{{8}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibcite{stajner-etal-2022-lexical}{{9}{2022}{{\v {S}tajner et~al.}}{{\v {S}tajner, Ferr\'{e}s, Shardlow, North, Zampieri, and Saggion}}}
\bibcite{wei-etal-2022-emergent}{{10}{2022}{{Wei et~al.}}{{Wei, Tay, Bommasani, Raffel, Zoph, Borgeaud, Yogatama, Bosma, Zhou, Metzler, Chi, Hashimoto, Vinyals, Liang, Dean, and Fedus}}}
\bibcite{zhang-etal-2022-opt}{{11}{2022}{{Zhang et~al.}}{{Zhang, Roller, Goyal, Artetxe, Chen, Chen, Dewan, Diab, Li, Lin, Mihaylov, Ott, Shleifer, Shuster, Simig, Koura, Sridhar, Wang, and Zettlemoyer}}}
\bibstyle{acl_natbib}
\newlabel{sec:prompts}{{A}{4}{Prompt Templates}{appendix.A}{}}
\newlabel{sec:prompts@cref}{{[appendix][1][2147483647]A}{[1][4][]4}}
\newlabel{sec:filters}{{C}{4}{Post-Filtering Operations}{appendix.C}{}}
\newlabel{sec:filters@cref}{{[appendix][3][2147483647]C}{[1][4][]4}}
\newlabel{tab:prompts}{{2}{5}{The English prompt templates used for querying the OpenAI model, including associated generation temperatures. Only written out ``\texttt {\n }'' symbols indicate newlines, visible line breaks are inserted for better legibility. Only top-most prompt template with conservative temperature was used in the single prompt (Run 1), as well as in the ensemble run (Run 2). All other prompts` were only included in the ensemble submission.\relax }{table.caption.3}{}}
\newlabel{tab:prompts@cref}{{[table][2][2147483647]2}{[1][4][]5}}
\citation{qiang-etal-2020-lexical}
\citation{ferres-etal-2017-adaptable}
\citation{qiang-etal-2020-lexical}
\citation{ferres-etal-2017-adaptable}
\citation{qiang-etal-2020-lexical}
\citation{ferres-etal-2017-adaptable}
\citation{qiang-etal-2020-lexical}
\citation{ferres-etal-2017-adaptable}
\newlabel{tab:spanish}{{3}{7}{Results on the Spanish language test set of the TSAR-2022 shared task, ranked by \emph {ACC@1} scores. Listed are our own results (\emph {Ensemble} and \emph {Single}), the two best-performing competing systems~(\emph {PresiUniv} and \emph {UoM\&MMU}), as well as provided baselines (\emph {LSBert}~\cite {qiang-etal-2020-lexical} and TUNER~\cite {ferres-etal-2017-adaptable}).\relax }{table.caption.4}{}}
\newlabel{tab:spanish@cref}{{[table][3][2147483647]3}{[1][6][]7}}
\newlabel{tab:portuguese}{{4}{7}{Results on the Portuguese language test set of the TSAR-2022 shared task, ranked by \emph {ACC@1} scores. Listed are our own results (\emph {Ensemble} and \emph {Single}), the two best-performing competing systems~(\emph {MANTIS} and \emph {UoM\&MMU}), as well as provided baselines (\emph {LSBert}~\cite {qiang-etal-2020-lexical} and TUNER~\cite {ferres-etal-2017-adaptable}).\relax }{table.caption.5}{}}
\newlabel{tab:portuguese@cref}{{[table][4][2147483647]4}{[1][6][]7}}
