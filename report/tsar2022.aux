\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{sutton-2019-bitter}
\citation{vaswani-etal-2017-attention,wei-etal-2022-emergent}
\citation{ferres-etal-2017-adaptable,qiang-etal-2020-lexical,stajner-etal-2022-lexical}
\citation{tsar-2022-findings}
\citation{brown-etal-2020-language}
\citation{thoppilan-etal-2022-lambda,bigscience-2022-bloom,zhang-etal-2022-opt}
\citation{qiang-etal-2020-lexical}
\citation{ferres-etal-2017-adaptable}
\citation{qiang-etal-2020-lexical}
\citation{ferres-etal-2017-adaptable}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:english}{{1}{3}{Results on the English language test set of the TSAR-2022 shared task, ranked by \emph {ACC@1} scores. Listed are our own results (\emph {Ensemble} and \emph {Single}), the two best-performing competing systems~(\emph {MANTIS} and \emph {UoM\&MMU}), as well as provided baselines (\emph {LSBert}~\cite {qiang-etal-2020-lexical} and TUNER~\cite {ferres-etal-2017-adaptable}).\relax }{table.caption.1}{}}
\newlabel{tab:english@cref}{{[table][1][]1}{[1][2][]3}}
\citation{bigscience-2022-bloom}
\citation{lacoste-etal-2019-quantifying}
\citation{schick-schutze-2021-generating}
\citation{lester-etal-2021-power}
\bibdata{anthology,custom}
\newlabel{tab:failures}{{2}{4}{Instances of observed failure classes in our system's predictions.\relax }{table.caption.2}{}}
\newlabel{tab:failures@cref}{{[table][2][]2}{[1][3][]4}}
\newlabel{sec:budget}{{3.4}{4}{Computational Limitations}{subsection.3.4}{}}
\newlabel{sec:budget@cref}{{[subsection][4][3]3.4}{[1][4][]4}}
\bibcite{bigscience-2022-bloom}{{1}{2022}{{BigScience}}{{}}}
\bibcite{brown-etal-2020-language}{{2}{2020}{{Brown et~al.}}{{Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and Amodei}}}
\bibcite{ferres-etal-2017-adaptable}{{3}{2017}{{Ferr{\'e}s et~al.}}{{Ferr{\'e}s, Saggion, and G{\'o}mez~Guinovart}}}
\bibcite{lacoste-etal-2019-quantifying}{{4}{2019}{{Lacoste et~al.}}{{Lacoste, Luccioni, Schmidt, and Dandres}}}
\bibcite{lester-etal-2021-power}{{5}{2021}{{Lester et~al.}}{{Lester, Al-Rfou, and Constant}}}
\bibcite{qiang-etal-2020-lexical}{{6}{2020}{{Qiang et~al.}}{{Qiang, Li, Yi, Yuan, and Wu}}}
\bibcite{tsar-2022-findings}{{7}{2022}{{Saggion et~al.}}{{Saggion, \v {S}tajner, Ferr{\'e}s, Sheang, Shardlow, North, and Zampieri}}}
\bibcite{schick-schutze-2021-generating}{{8}{2021}{{Schick and Sch{\"u}tze}}{{}}}
\bibcite{sutton-2019-bitter}{{9}{2019}{{Sutton}}{{}}}
\bibcite{thoppilan-etal-2022-lambda}{{10}{2022}{{Thoppilan et~al.}}{{Thoppilan, Freitas, Hall, Shazeer, Kulshreshtha, Cheng, Jin, Bos, Baker, Du, Li, Lee, Zheng, Ghafouri, Menegali, Huang, Krikun, Lepikhin, Qin, Chen, Xu, Chen, Roberts, Bosma, Zhou, Chang, Krivokon, Rusch, Pickett, Meier{-}Hellstern, Morris, Doshi, Santos, Duke, Soraker, Zevenbergen, Prabhakaran, Diaz, Hutchinson, Olson, Molina, Hoffman{-}John, Lee, Aroyo, Rajakumar, Butryna, Lamm, Kuzmina, Fenton, Cohen, Bernstein, Kurzweil, Aguera{-}Arcas, Cui, Croak, Chi, and Le}}}
\bibcite{vaswani-etal-2017-attention}{{11}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibcite{stajner-etal-2022-lexical}{{12}{2022}{{\v {S}tajner et~al.}}{{\v {S}tajner, Ferr\'{e}s, Shardlow, North, Zampieri, and Saggion}}}
\bibcite{wei-etal-2022-emergent}{{13}{2022}{{Wei et~al.}}{{Wei, Tay, Bommasani, Raffel, Zoph, Borgeaud, Yogatama, Bosma, Zhou, Metzler, Chi, Hashimoto, Vinyals, Liang, Dean, and Fedus}}}
\bibcite{zhang-etal-2022-opt}{{14}{2022}{{Zhang et~al.}}{{Zhang, Roller, Goyal, Artetxe, Chen, Chen, Dewan, Diab, Li, Lin, Mihaylov, Ott, Shleifer, Shuster, Simig, Koura, Sridhar, Wang, and Zettlemoyer}}}
\bibstyle{acl_natbib}
\citation{qiang-etal-2020-lexical}
\citation{ferres-etal-2017-adaptable}
\citation{qiang-etal-2020-lexical}
\citation{ferres-etal-2017-adaptable}
\citation{qiang-etal-2020-lexical}
\citation{ferres-etal-2017-adaptable}
\citation{qiang-etal-2020-lexical}
\citation{ferres-etal-2017-adaptable}
\newlabel{sec:prompts}{{A}{6}{Prompt Templates}{appendix.A}{}}
\newlabel{sec:prompts@cref}{{[appendix][1][2147483647]A}{[1][6][]6}}
\newlabel{sec:filters}{{C}{6}{Post-Filtering Operations}{appendix.C}{}}
\newlabel{sec:filters@cref}{{[appendix][3][2147483647]C}{[1][6][]6}}
\newlabel{tab:prompts}{{3}{7}{The English prompt templates used for querying the OpenAI model, including associated generation temperatures. Only written out ``\texttt {\n }'' symbols indicate newlines, visible line breaks are inserted for better legibility. Only top-most prompt template with conservative temperature was used in the single prompt (Run 1), as well as in the ensemble run (Run 2). All other prompts were only included in the ensemble submission.\relax }{table.caption.8}{}}
\newlabel{tab:prompts@cref}{{[table][3][2147483647]3}{[1][6][]7}}
\newlabel{tab:spanish}{{4}{8}{Results on the Spanish language test set of the TSAR-2022 shared task, ranked by \emph {ACC@1} scores. Listed are our own results (\emph {Ensemble} and \emph {Single}), the two best-performing competing systems~(\emph {PresiUniv} and \emph {UoM\&MMU}), as well as provided baselines (\emph {LSBert}~\cite {qiang-etal-2020-lexical} and TUNER~\cite {ferres-etal-2017-adaptable}).\relax }{table.caption.9}{}}
\newlabel{tab:spanish@cref}{{[table][4][2147483647]4}{[1][6][]8}}
\newlabel{tab:portuguese}{{5}{8}{Results on the Portuguese language test set of the TSAR-2022 shared task, ranked by \emph {ACC@1} scores. Listed are our own results (\emph {Ensemble} and \emph {Single}), the two best-performing competing systems~(\emph {GMU-WLV} and \emph {Cental}), as well as provided baselines (\emph {LSBert}~\cite {qiang-etal-2020-lexical} and TUNER~\cite {ferres-etal-2017-adaptable}).\relax }{table.caption.10}{}}
\newlabel{tab:portuguese@cref}{{[table][5][2147483647]5}{[1][6][]8}}
\gdef \@abspage@last{8}
